import matplotlib.pyplot as plt
import numpy as np

learning_rates = [0.1, 0.01, 0.001]
num_epochs = 10
# two lists with the training losses per batch, for learning rates [0.1, 0.01, 0.001]
train_loss_per_lr = [[0.010245052532935502, 0.2825819157442111, 0.1558058585649655, 0.16947445939761294, 0.08712844775455643, 0.15363039440170073, 0.11071075145436249, 0.07306650548723663, 0.061834163544763426, 0.09026486301904516], [0.008052110830411335, 0.035233551214751885, 0.03206759184312755, 0.03008085170400486, 0.02686432592662764, 0.0266644437126662, 0.024627483553356595, 0.023447585204010638, 0.02336086817239047, 0.022000191429187896], [0.012512876004471209, 0.029347421557978513, 0.02838100918117701, 0.026093654160800457, 0.023928459227820973, 0.022861134981422268, 0.021519707267994088, 0.021212252467584545, 0.020499036349713885, 0.019495438298897817]]
eval_loss_per_lr = [[4.531900468763414, 3.7562968652326982, 2.3397942781448364, 2.4500694694099847, 1.9352056220337586, 1.9220268411950752, 2.010038028706561, 1.635647980066446, 1.408475664945749, 1.2646156392254673], [0.25638003991200375, 0.45298297752390854, 0.4441244726652627, 0.4552796279991066, 0.4406847200550876, 0.4373515798495366, 0.4283215505081219, 0.41852684990390315, 0.4226306748914195, 0.423211096407293], [0.25973168834225163, 0.3245666583815774, 0.33437128315915116, 0.3346361540831052, 0.33792288028276884, 0.33618539080515014, 0.33848296646233444, 0.3356791511996762, 0.33516318801340167, 0.3363574697421147]]


for i in range(len(learning_rates)):
          
    #plot the losses
    plt.plot(range(num_epochs), train_loss_per_lr[i], '-', label = f" training loss for learning rate {learning_rates[i]}")
    plt.plot(range(num_epochs), eval_loss_per_lr[i], '--', label = f" evaluation loss for learning rate {learning_rates[i]}")
plt.legend()
plt.xlabel("epoch")
plt.ylabel("loss")
plt.yscale("log")

plt.show()
print(f"training loss per learning rate = {train_loss_per_lr}")
print(f"evaluation loss per learning rate = {eval_loss_per_lr}")